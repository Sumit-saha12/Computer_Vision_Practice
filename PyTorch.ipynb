{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KPDTrM_7xNRx"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cPtcBuoCxbCS",
        "outputId": "fd0b1807-efd8-4e53-fc0b-2f263062315f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.5.1'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_q9jEizxn0k",
        "outputId": "fe6790e5-5148-454c-f63a-6e49bc695787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2)\n"
          ]
        }
      ],
      "source": [
        "scalar = torch.tensor(2)\n",
        "print(scalar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOoQTh2b5U8c",
        "outputId": "c99c1238-4c00-4f2a-d3c0-4594837dd6e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension of scalar is 0\n"
          ]
        }
      ],
      "source": [
        "print(f'Dimension of scalar is {scalar.ndim}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjM5VGqV5f2W",
        "outputId": "c1887df8-296c-4c5a-dd5b-5323ea2d7faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "print(scalar.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_OY-UQL59ZT",
        "outputId": "2b531266-1418-46b3-be45-b0d09c7e44df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1])\n",
            "Dimension of vector is 1\n"
          ]
        }
      ],
      "source": [
        "vector = torch.tensor([0,1])\n",
        "print(vector)\n",
        "print(f'Dimension of vector is {vector.ndim}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw0zo9468e2x",
        "outputId": "f4b6ce5c-9c25-410d-f437-24260c696c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 1],\n",
            "        [1, 2]])\n",
            "Dimension of matrix is 2\n"
          ]
        }
      ],
      "source": [
        "matrix = torch.tensor([[0,1],\n",
        "                      [1,2]])\n",
        "print(matrix)\n",
        "print(f'Dimension of matrix is {matrix.ndim}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqTFTGwV9ZfO",
        "outputId": "02d3b7fb-4a8c-428f-ec35-1364e8e493d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "print(matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV5NzITV9ayQ",
        "outputId": "d621beb3-3715-4d00-eb42-906d414b6d76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[0, 1],\n",
            "         [1, 2],\n",
            "         [2, 3]]])\n",
            "Dimension of matrix is 3\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.tensor([[[0,1],\n",
        "                      [1,2],\n",
        "                       [2,3]]])\n",
        "print(tensor)\n",
        "print(f'Dimension of matrix is {tensor.ndim}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uNG_E-w9nwb",
        "outputId": "f72a92fb-d810-4b78-dddb-ec5c0ea8b3eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 2])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor.shape ## 1 Dimention of shape 3,2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2BZzKvy-EBn",
        "outputId": "7767f5f2-205e-40ff-d6cd-fe4c02abdcdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[0, 1],\n",
            "         [1, 2],\n",
            "         [2, 3]]])\n",
            "Dimension of matrix is 3\n",
            "torch.Size([1, 3, 2])\n",
            "tensor([[0, 1],\n",
            "        [1, 2],\n",
            "        [2, 3]])\n",
            "tensor([1, 2])\n",
            "tensor([2, 3])\n",
            "tensor(3)\n",
            "tensor([[1, 2, 3]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.tensor([[[0,1],\n",
        "                      [1,2],\n",
        "                       [2,3]]])\n",
        "print(tensor)\n",
        "print(f'Dimension of matrix is {tensor.ndim}')\n",
        "print(tensor.shape)\n",
        "## Indexing\n",
        "\n",
        "print(tensor[0])\n",
        "print(tensor[0][1])\n",
        "print(tensor[0][2])\n",
        "print(tensor[0][2][1])\n",
        "\n",
        "print(tensor[:,:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eU0QW8JCK3m",
        "outputId": "e164fee6-a2f1-41a9-da6c-e9edcf1bec2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0131, 0.2795, 0.2651],\n",
            "        [0.7739, 0.2198, 0.0253],\n",
            "        [0.4965, 0.5074, 0.5276]])\n",
            "2\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "## Random tensors\n",
        "\n",
        "random_tensor = torch.rand(size=(3,3))\n",
        "\n",
        "print(random_tensor)\n",
        "print(random_tensor.ndim)\n",
        "print(random_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ReJoNNu9JuiH",
        "outputId": "adc98f76-d3b0-4cec-e096-4eb623ef0399"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[9.8654e-01, 1.4108e-01, 5.6568e-01, 1.3322e-01, 4.5777e-01, 1.4178e-01,\n",
            "         1.7380e-01, 9.1889e-01, 5.6555e-01, 1.8050e-01, 7.7099e-01, 6.1992e-01,\n",
            "         8.3883e-01, 1.5904e-02, 4.1091e-01, 4.3242e-01, 7.4643e-01, 9.9280e-01,\n",
            "         7.8578e-01, 8.1756e-01, 1.5931e-01, 9.1955e-01, 6.2166e-01, 6.7653e-01,\n",
            "         8.5441e-01, 2.2726e-02, 8.6191e-02, 5.4167e-01, 6.1648e-01, 4.0504e-01,\n",
            "         7.7791e-01, 4.5533e-01, 5.5769e-01, 1.2727e-01, 1.8483e-01, 8.3720e-01,\n",
            "         9.1149e-01, 7.6812e-01, 8.3361e-01, 1.5754e-01, 8.9977e-03, 5.4130e-01,\n",
            "         9.5029e-01, 8.3990e-01, 5.6207e-01, 8.7428e-01, 8.2656e-01, 5.8491e-01,\n",
            "         6.3492e-01, 6.5496e-01, 6.7565e-01, 8.6020e-01, 8.8832e-02, 4.4644e-01,\n",
            "         3.6168e-02, 3.2030e-01, 8.7796e-01, 6.2955e-01, 2.3235e-01, 3.0409e-01,\n",
            "         1.4817e-01, 4.1300e-01, 9.3557e-01, 9.7983e-01, 7.6944e-01, 1.8497e-01,\n",
            "         2.4378e-01, 5.0500e-01, 1.1689e-02, 1.4583e-01, 5.4899e-02, 3.7287e-01,\n",
            "         9.1843e-01, 4.0855e-01, 1.5798e-01, 3.7702e-01, 3.8410e-01, 5.2133e-01,\n",
            "         9.1144e-01, 1.9497e-01, 2.5016e-01, 2.7824e-01, 3.2348e-02, 7.0688e-01,\n",
            "         3.1631e-02, 8.4247e-01, 1.8022e-01, 2.9495e-01, 9.7982e-01, 7.4338e-01,\n",
            "         4.7440e-01, 4.8282e-01, 6.6854e-01, 8.4540e-01, 3.2334e-01, 1.6139e-02,\n",
            "         7.0957e-01, 7.6487e-01, 7.5226e-01, 8.8670e-01],\n",
            "        [6.7917e-01, 8.2657e-01, 4.8122e-01, 8.6800e-01, 6.7674e-01, 8.8107e-01,\n",
            "         5.4553e-01, 8.6831e-01, 4.5981e-01, 2.4240e-01, 6.6068e-01, 5.1761e-01,\n",
            "         9.5801e-02, 9.7632e-01, 1.8730e-01, 2.9389e-01, 2.2584e-01, 8.8640e-01,\n",
            "         5.1315e-01, 2.8473e-02, 2.1002e-01, 6.3476e-01, 3.9214e-01, 4.2114e-01,\n",
            "         6.4935e-01, 2.2591e-01, 2.3848e-01, 5.3767e-01, 5.7757e-01, 5.7364e-01,\n",
            "         3.2867e-01, 6.7752e-01, 5.7481e-01, 1.1936e-01, 4.1984e-01, 9.4750e-01,\n",
            "         4.8785e-01, 4.5529e-01, 3.0439e-01, 6.3419e-01, 7.8613e-01, 5.8105e-01,\n",
            "         5.1355e-01, 6.2699e-01, 5.8049e-01, 4.1367e-01, 6.5559e-01, 4.5204e-01,\n",
            "         3.2875e-01, 5.7232e-01, 8.2040e-01, 1.5354e-01, 7.8282e-01, 1.5062e-01,\n",
            "         8.6660e-02, 2.4805e-01, 5.0246e-01, 1.2094e-01, 7.5458e-01, 3.3303e-01,\n",
            "         6.7206e-01, 2.1827e-01, 7.5873e-02, 9.1781e-01, 5.5244e-01, 9.8814e-01,\n",
            "         9.1804e-01, 8.1040e-01, 4.9616e-01, 6.3683e-01, 7.3285e-01, 5.8756e-01,\n",
            "         7.2419e-01, 4.2755e-01, 2.6432e-01, 7.4267e-01, 4.2469e-01, 4.8707e-01,\n",
            "         1.1862e-01, 1.4831e-01, 8.9732e-01, 1.0491e-01, 3.2941e-02, 5.9012e-01,\n",
            "         8.1524e-01, 2.0419e-02, 1.9393e-01, 6.8731e-01, 8.6196e-01, 9.8168e-01,\n",
            "         6.0214e-01, 5.0439e-01, 3.6937e-01, 2.5634e-01, 4.7963e-01, 5.7947e-01,\n",
            "         7.6431e-01, 4.3590e-01, 8.2511e-01, 9.1296e-01],\n",
            "        [2.1984e-01, 9.5975e-01, 8.0392e-01, 5.6402e-01, 3.6772e-01, 3.5593e-01,\n",
            "         1.5700e-02, 5.2169e-01, 3.4781e-01, 6.5453e-01, 3.2621e-01, 8.0163e-01,\n",
            "         1.6189e-01, 8.5034e-01, 1.0380e-01, 1.7434e-01, 3.6807e-01, 2.8804e-01,\n",
            "         6.8607e-01, 5.5832e-01, 5.2876e-01, 1.9956e-01, 8.2005e-01, 3.7116e-01,\n",
            "         1.2394e-01, 5.9759e-01, 1.5733e-01, 1.3496e-01, 1.4102e-01, 1.3315e-01,\n",
            "         8.1027e-01, 3.0679e-01, 4.2155e-01, 1.4006e-01, 7.3478e-01, 1.5888e-01,\n",
            "         2.9439e-01, 4.3718e-01, 8.3229e-01, 6.8849e-01, 3.8250e-01, 2.6585e-01,\n",
            "         2.5066e-01, 6.9738e-02, 9.3002e-01, 2.1508e-01, 6.9356e-01, 8.0538e-01,\n",
            "         4.7448e-02, 1.4714e-01, 8.2624e-01, 7.0185e-02, 5.7770e-01, 5.1432e-01,\n",
            "         8.3381e-01, 2.2197e-01, 1.4235e-01, 2.2739e-01, 2.4686e-01, 9.8296e-01,\n",
            "         2.7748e-01, 1.6287e-01, 6.5367e-02, 8.7304e-01, 5.6954e-01, 7.3080e-01,\n",
            "         9.4540e-01, 8.1934e-01, 1.9917e-01, 1.2069e-01, 4.0776e-01, 2.7775e-01,\n",
            "         6.5965e-01, 8.2782e-01, 5.1744e-01, 2.4016e-01, 3.8473e-01, 1.0728e-01,\n",
            "         2.7868e-01, 3.1150e-02, 4.3305e-02, 8.6921e-01, 9.6632e-01, 3.2477e-01,\n",
            "         3.3614e-01, 7.6344e-01, 7.8813e-01, 2.6197e-01, 6.1018e-01, 9.5566e-01,\n",
            "         4.2215e-01, 9.5207e-01, 5.1508e-01, 2.8929e-01, 8.2238e-01, 5.7449e-02,\n",
            "         4.2519e-01, 8.7396e-01, 9.0035e-01, 8.1080e-01],\n",
            "        [5.0837e-01, 1.1285e-01, 5.9640e-01, 7.3018e-01, 9.2853e-01, 4.0838e-02,\n",
            "         6.9167e-01, 5.6107e-01, 8.1479e-01, 9.0334e-03, 1.6059e-01, 4.0080e-02,\n",
            "         2.1656e-01, 7.7821e-01, 6.3281e-01, 1.4422e-01, 5.2862e-01, 1.4003e-01,\n",
            "         8.6103e-02, 5.3963e-02, 7.2614e-02, 3.7881e-01, 7.2352e-01, 8.6043e-01,\n",
            "         9.2799e-01, 2.4425e-01, 6.5150e-01, 9.6765e-01, 5.8182e-01, 9.1352e-01,\n",
            "         1.4183e-01, 9.8961e-02, 6.2709e-02, 6.2200e-02, 6.5916e-01, 3.0346e-02,\n",
            "         4.1002e-01, 9.8419e-01, 7.7287e-01, 8.0081e-01, 3.0358e-01, 5.2272e-01,\n",
            "         6.0295e-01, 6.1704e-01, 8.7559e-01, 1.9710e-01, 5.1882e-01, 6.4160e-01,\n",
            "         4.5068e-02, 2.2226e-01, 6.7395e-01, 7.8359e-01, 9.0584e-01, 8.1961e-01,\n",
            "         8.4587e-01, 4.7929e-01, 4.4147e-01, 9.8289e-01, 1.2679e-01, 4.6122e-01,\n",
            "         1.6201e-03, 4.2717e-01, 9.0362e-01, 9.4409e-01, 8.0914e-01, 5.3952e-01,\n",
            "         7.3819e-01, 3.7583e-01, 8.6682e-01, 2.1199e-01, 4.6262e-01, 2.4638e-01,\n",
            "         8.5248e-01, 6.6607e-01, 6.9922e-01, 5.3159e-01, 5.8307e-01, 5.5663e-01,\n",
            "         9.2150e-01, 7.7114e-01, 2.9811e-01, 4.1918e-02, 4.6060e-01, 7.9110e-01,\n",
            "         7.7624e-01, 6.2426e-01, 4.6131e-01, 8.1281e-01, 3.7722e-01, 2.5928e-01,\n",
            "         2.8250e-01, 1.3929e-01, 1.7296e-02, 9.0937e-01, 5.4100e-01, 9.8667e-01,\n",
            "         1.6562e-01, 3.4225e-01, 8.1709e-01, 2.6567e-01],\n",
            "        [2.9175e-01, 8.4108e-01, 9.9367e-01, 2.5628e-01, 9.0534e-01, 3.0624e-01,\n",
            "         4.3951e-01, 8.0711e-01, 2.0974e-01, 8.2914e-01, 8.4978e-01, 9.4983e-01,\n",
            "         2.2205e-01, 2.8496e-01, 4.7226e-01, 8.3786e-01, 4.5703e-02, 1.8960e-01,\n",
            "         3.7107e-01, 3.6160e-01, 7.9992e-01, 3.9738e-01, 3.0151e-01, 6.0692e-01,\n",
            "         3.5713e-01, 2.3203e-01, 8.2789e-01, 8.1693e-01, 9.6434e-01, 9.7179e-01,\n",
            "         8.8049e-02, 2.9440e-01, 1.3551e-01, 6.2873e-01, 5.3189e-01, 5.5508e-01,\n",
            "         2.9075e-01, 3.3959e-01, 3.8082e-01, 5.9306e-01, 8.7171e-01, 9.8185e-01,\n",
            "         1.3560e-01, 9.7448e-01, 7.7055e-02, 7.7321e-01, 5.3985e-01, 6.6695e-01,\n",
            "         2.9783e-02, 9.2199e-01, 6.1689e-01, 2.4757e-01, 5.1221e-01, 5.8500e-01,\n",
            "         7.8008e-01, 8.1859e-01, 5.1693e-01, 7.7738e-01, 8.1095e-01, 3.1801e-01,\n",
            "         1.8279e-01, 4.3150e-01, 9.9109e-02, 1.0807e-01, 8.9184e-01, 1.4488e-01,\n",
            "         8.9477e-01, 6.9010e-01, 5.5460e-01, 7.4628e-01, 2.2780e-01, 3.7895e-01,\n",
            "         4.1916e-01, 3.1627e-01, 7.6243e-01, 5.5893e-01, 7.6832e-02, 7.7406e-01,\n",
            "         6.6173e-01, 8.8659e-02, 4.4144e-01, 6.3657e-01, 3.2034e-01, 1.6163e-01,\n",
            "         8.7185e-01, 6.2153e-02, 6.2219e-01, 7.1009e-01, 1.6178e-01, 8.6236e-01,\n",
            "         2.9689e-01, 5.0813e-01, 9.5944e-01, 4.2278e-01, 4.7316e-01, 2.9675e-01,\n",
            "         1.2173e-01, 6.6251e-01, 2.7096e-04, 1.2621e-01]])\n"
          ]
        }
      ],
      "source": [
        "input = 5\n",
        "output = 100\n",
        "\n",
        "weight_tensor = torch.rand(size=(input,output))\n",
        "print(weight_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s6VXT7Kxc6W",
        "outputId": "73a8ec6c-78db-4b08-c1bc-97db88220729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "torch.Size([3, 4])\n",
            "tensor([[  0.,   0.,   0.,   0.],\n",
            "        [  0.,   0.,   0., 255.],\n",
            "        [  0.,   0.,   0.,   0.]])\n"
          ]
        }
      ],
      "source": [
        "zeros = torch.zeros(size=(3,4))\n",
        "\n",
        "print(zeros.ndim)\n",
        "\n",
        "print(zeros.shape)\n",
        "zeros[1][3]=255\n",
        "print(zeros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "7fnFapHKxzeU",
        "outputId": "cc34058c-bfa0-4187-f52e-87b28b7a8b1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x149dd0190>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(zeros,cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8mJjBdsyiOf",
        "outputId": "a718d975-0424-422a-eb92-6b6b70cb7e4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=list(range(0,9))\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDiJn7uXysuM",
        "outputId": "7913babb-2069-4cf7-deb3-8b56eba0c036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8]\n"
          ]
        }
      ],
      "source": [
        "range1 = torch.arange(start=0,end=9,step=1)\n",
        "print(range1.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "syfwRjh7zKlY",
        "outputId": "6b1652d3-bb74-4a00-c479-8cd3cb4b32c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[255., 255., 255.],\n",
            "        [255., 255., 255.],\n",
            "        [255., 255., 255.]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1553777d0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dummy_image_zeros = torch.ones_like(input = random_tensor)*255\n",
        "dummy_image_zeros_np = dummy_image_zeros.numpy()\n",
        "print(dummy_image_zeros)\n",
        "plt.imshow(dummy_image_zeros,cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ryh8jn_20-i",
        "outputId": "330630f6-554e-45f4-c5eb-9642be621ffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float32\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "tensor_example = torch.tensor([0.,1.,2.],  ## By default goiing to INT64\n",
        "                              dtype=None,\n",
        "                              device=None)\n",
        "print(tensor_example.dtype)\n",
        "print(tensor_example.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe2ZsiNW4spm",
        "outputId": "fb269661-1bc1-46df-8592-1c3dd5592550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.int64\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "tensor_example = torch.tensor([0,1,2],  ## By default goiing to INT64\n",
        "                              dtype=None,\n",
        "                              device=None)\n",
        "print(tensor_example.dtype)\n",
        "print(tensor_example.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5uwAi4N452C",
        "outputId": "788a0f41-4199-4d2d-f7d1-aeaeb8f675be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([11, 12, 13, 14, 15])\n",
            "tensor([11, 12, 13, 14, 15])\n"
          ]
        }
      ],
      "source": [
        "## Tensor Manipulation\n",
        "\n",
        "tensor_t = torch.tensor([1,2,3,4,5])\n",
        "\n",
        "# Addition\n",
        "print(tensor_t+10)\n",
        "print(tensor_t.add(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "collapsed": true,
        "id": "uZe2zKRW45tC",
        "outputId": "ab6a5c63-b44f-4714-aca4-a2fbc81e3c33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nmatrix_a.shape = X,Y\\nmatrix_b.shape = A,B\\nCondition -> Y=A\\nOutput dimension = X,B\\n'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Dot Product\n",
        "\n",
        "## 2,3 dot product 2,3\n",
        "\n",
        "# Rule\n",
        "'''\n",
        "matrix_a.shape = X,Y\n",
        "matrix_b.shape = A,B\n",
        "Condition -> Y=A\n",
        "Output dimension = X,B\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwOWrddt6eMd",
        "outputId": "98f6471a-23a4-423b-80d5-d8dc5e3c8de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7]])\n",
            "tensor([[3, 7, 8],\n",
            "        [2, 5, 9]])\n",
            "tensor([[ 82, 100],\n",
            "        [ 78,  94]])\n"
          ]
        }
      ],
      "source": [
        "matrix_1 = torch.tensor([[1,2,3],[4,5,6]])\n",
        "matrix_2 = torch.tensor([[2,3],[4,5],[6,7]])\n",
        "matrix_3 = torch.tensor([[3,2],[7,5],[8,9]])\n",
        "matrix_3 = matrix_3.T\n",
        "print(matrix_1)\n",
        "print(matrix_2)\n",
        "print(matrix_3)\n",
        "\n",
        "mat = torch.matmul(matrix_3,matrix_2)\n",
        "print(mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v40utp5L9qN7",
        "outputId": "123c08ca-9f00-4b7a-dded-4ee140db7f97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float16\n",
            "Min no. in a tensor -100.0\n",
            "Max no. in a tensor 2000.0\n",
            "Mean no. in a tensor 224.5\n",
            "Index where max value occurs 7 and value is 2000.0\n",
            "Index where min value occurs 8 and value is -100.0\n"
          ]
        }
      ],
      "source": [
        "##Aggregation functions\n",
        "\n",
        "torch_agg = torch.tensor([1,2,3,4,5,6,100,2000,-100],dtype=torch.float16)\n",
        "print(torch_agg.dtype)\n",
        "print(f'Min no. in a tensor {torch_agg.min()}')\n",
        "print(f'Max no. in a tensor {torch_agg.max()}')\n",
        "\n",
        "# torch_agg = torch_agg.type(torch.float16)\n",
        "\n",
        "print(f'Mean no. in a tensor {torch_agg.mean()}')\n",
        "\n",
        "print(f'Index where max value occurs {torch_agg.argmax()} and value is {torch_agg[torch_agg.argmax()].item()}')\n",
        "print(f'Index where min value occurs {torch_agg.argmin()} and value is {torch_agg[torch_agg.argmin()].item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uym8dk_XQSBZ",
        "outputId": "aa83dde6-6a2b-4ce0-8e85-00626d595317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.7402, -1.0829,  0.0230, -0.7798],\n",
            "        [-0.2833,  2.2666,  1.8383,  0.4818],\n",
            "        [ 0.1614,  1.0515,  0.5320, -1.3373],\n",
            "        [ 0.3149,  0.9783,  0.9469, -0.4519]])\n",
            "torch.Size([4, 4])\n",
            "2\n",
            "--------------------------------------------------\n",
            "tensor([-1.7402, -1.0829,  0.0230, -0.7798, -0.2833,  2.2666,  1.8383,  0.4818,\n",
            "         0.1614,  1.0515,  0.5320, -1.3373,  0.3149,  0.9783,  0.9469, -0.4519])\n",
            "torch.Size([16])\n",
            "1\n",
            "--------------------------------------------------\n",
            "tensor([-1.7402, -1.0829,  0.0230, -0.7798, -0.2833,  2.2666,  1.8383,  0.4818,\n",
            "         0.1614,  1.0515,  0.5320, -1.3373,  0.3149,  0.9783,  0.9469, -0.4519])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "tensor_matrix = torch.randn(4,4)\n",
        "print(tensor_matrix)\n",
        "print(tensor_matrix.shape)\n",
        "print(tensor_matrix.ndim)\n",
        "\n",
        "print('-'*50)\n",
        "\n",
        "tensor_matrix_view1 = tensor_matrix.view(16)\n",
        "print(tensor_matrix_view1)\n",
        "print(tensor_matrix_view1.shape)\n",
        "print(tensor_matrix_view1.ndim)\n",
        "\n",
        "print('-'*50)\n",
        "\n",
        "tensor_matrix_reshape = torch.reshape(tensor_matrix,(-1,))\n",
        "print(tensor_matrix_reshape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RVxpX4lQXno",
        "outputId": "2409c6a6-5d8a-41bc-dc1c-029564b225df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.0938, -1.3556,  1.5514,  0.5317,  0.6368,  0.4717, -0.8492, -0.8390,\n",
            "         0.1908, -0.0042, -1.9915,  0.4275, -0.8088,  0.3853, -0.2810,  0.5681])\n",
            "torch.Size([16])\n",
            "1\n",
            "--------------------------------------------------\n",
            "tensor([[ 0.0938, -1.3556,  1.5514,  0.5317],\n",
            "        [ 0.6368,  0.4717, -0.8492, -0.8390],\n",
            "        [ 0.1908, -0.0042, -1.9915,  0.4275],\n",
            "        [-0.8088,  0.3853, -0.2810,  0.5681]])\n",
            "torch.Size([4, 4])\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "## reshape\n",
        "\n",
        "torch_matrix = torch.randn(16)\n",
        "print(torch_matrix)\n",
        "print(torch_matrix.shape)\n",
        "print(torch_matrix.ndim)\n",
        "\n",
        "print('-'*50)\n",
        "\n",
        "torch_matrix_reshape = torch.reshape(torch_matrix,(4,4))\n",
        "print(torch_matrix_reshape)\n",
        "print(torch_matrix_reshape.shape)\n",
        "print(torch_matrix_reshape.ndim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ7bUO-ZXUgz",
        "outputId": "537f0078-6f1d-4a55-da5b-60fbdf006f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1.0941, -0.0848, -1.0617],\n",
            "        [ 0.7994, -0.2156,  1.2703]])\n",
            "torch.Size([2, 3])\n",
            "2\n",
            "--------------------------------------------------\n",
            "tensor([[-2.1567,  0.7826, -0.0200],\n",
            "        [-0.2541, -0.3116,  1.6336]])\n",
            "torch.Size([2, 3])\n",
            "2\n",
            "--------------------------------------------------\n",
            "tensor([[[ 1.0941, -0.0848, -1.0617],\n",
            "         [ 0.7994, -0.2156,  1.2703]],\n",
            "\n",
            "        [[-2.1567,  0.7826, -0.0200],\n",
            "         [-0.2541, -0.3116,  1.6336]]])\n",
            "torch.Size([2, 2, 3])\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "#stack\n",
        "\n",
        "random_stack = torch.randn(2,3)\n",
        "random_stack2 = torch.randn(2,3)\n",
        "\n",
        "print(random_stack)\n",
        "print(random_stack.shape)\n",
        "print(random_stack.ndim)\n",
        "\n",
        "print('-'*50)\n",
        "\n",
        "print(random_stack2)\n",
        "print(random_stack2.shape)\n",
        "print(random_stack2.ndim)\n",
        "\n",
        "print('-'*50)\n",
        "\n",
        "stack_matrix = torch.stack([random_stack,random_stack2])\n",
        "print(stack_matrix)\n",
        "print(stack_matrix.shape)\n",
        "print(stack_matrix.ndim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "765zHmwRGmon"
      },
      "source": [
        "# Pytorch - Intermediate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "B3m88mROGmJF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "NyNNXwa9Hm6S"
      },
      "outputs": [],
      "source": [
        "## Input Data\n",
        "\n",
        "X = torch.tensor([[1.0],[2.0],[3.0],[4.0]])\n",
        "# X = torch.tensor([1.0,2.0,3.0,4.0])\n",
        "\n",
        "## Output Data\n",
        "\n",
        "Y = torch.tensor([[2.0],[4.0],[6.0],[8.0]])\n",
        "# Y = torch.tensor([2.0,4.0,6.0,8.0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "-_f8toWeIFjN"
      },
      "outputs": [],
      "source": [
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    ## Define model's parameter\n",
        "    self.linear = nn.Linear(1,1)\n",
        "  def forward(self,x):\n",
        "    out = self.linear(x)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "hzoi5seJKABW"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "P1iJ_wbcMNoG"
      },
      "outputs": [],
      "source": [
        "## Define loss function\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimiser = torch.optim.SGD(model.parameters(),lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA0oFu6sM52Z",
        "outputId": "2135bf2a-7805-42d0-8e40-0c60c4db5369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 : Loss 52.1611442565918\n",
            "Epoch 2 : Loss 23.428483963012695\n",
            "Epoch 3 : Loss 10.527507781982422\n",
            "Epoch 4 : Loss 4.7347002029418945\n",
            "Epoch 5 : Loss 2.133362293243408\n",
            "Epoch 6 : Loss 0.9649609923362732\n",
            "Epoch 7 : Loss 0.4399506151676178\n",
            "Epoch 8 : Loss 0.20383521914482117\n",
            "Epoch 9 : Loss 0.09745180606842041\n",
            "Epoch 10 : Loss 0.049337632954120636\n",
            "Epoch 11 : Loss 0.027405861765146255\n",
            "Epoch 12 : Loss 0.017249053344130516\n",
            "Epoch 13 : Loss 0.012397211976349354\n"
          ]
        }
      ],
      "source": [
        "num_epoch = 13\n",
        "\n",
        "for epochs in range(num_epoch):\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # compute Loss\n",
        "\n",
        "  loss = criterion(y_pred,Y)\n",
        "\n",
        "  optimiser.zero_grad() ## Clearing old gradients\n",
        "\n",
        "  loss.backward() ## Backpropagation : Computer Gradients\n",
        "\n",
        "  optimiser.step() ## Updating weights\n",
        "\n",
        "  print(f'Epoch {epochs+1} : Loss {loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FzYv8GaPRbS",
        "outputId": "7535471a-57f9-4d83-a6a4-4e1a245d66c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Weight : 1.9368280172348022\n",
            "Model Bias : 0.22832898795604706\n"
          ]
        }
      ],
      "source": [
        "print(f'Model Weight : {model.linear.weight.item()}')\n",
        "print(f'Model Bias : {model.linear.bias.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsz2FFFBTVrj",
        "outputId": "5f0bb579-120f-4ef5-c68f-8728cb36763c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input value: tensor([1., 2., 3., 4.])\n",
            "Input value: [1. 2. 3. 4.]\n",
            "--------------------------------------------------\n",
            "Prediction of Y: [2.165157  4.101985  6.038813  7.9756413]\n",
            "--------------------------------------------------\n",
            "Actual of Y: [2. 4. 6. 8.]\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  predicted = model(X)\n",
        "  print(f'Input value: {X[:,0]}')\n",
        "  print(f'Input value: {X[:,0].numpy()}')\n",
        "  print('-'*50)\n",
        "\n",
        "  print(f'Prediction of Y: {predicted.squeeze().numpy()}')\n",
        "  print('-'*50)\n",
        "  print(f'Actual of Y: {Y.squeeze().numpy()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zA0vE7mWTpaw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAr21CkoTppI",
        "outputId": "9c2ef5b1-ab8c-4371-e53c-7a578de2c1cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[3]]])\n",
            "tensor(3)\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[[3]]])\n",
        "print(a)\n",
        "a_new = a.squeeze()\n",
        "print(a_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT9wn_GWdfUi"
      },
      "source": [
        "# Pytorch - Advance\n",
        "\n",
        "- Sequential\n",
        "- Functional API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "3HOhy5A8ddZf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCUDs73YdtOh",
        "outputId": "52fa9e3a-fdb4-4b00-d94f-736b1246cb18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=20, out_features=64, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=32, out_features=5, bias=True)\n",
            ")\n",
            "tensor([[ 0.2773, -0.0157,  0.1542, -0.2226, -0.0235],\n",
            "        [ 0.2238,  0.1284,  0.1431, -0.2024,  0.1204],\n",
            "        [ 0.2219, -0.0628,  0.1643, -0.2554,  0.0139],\n",
            "        [ 0.2489,  0.0667,  0.1801, -0.1805,  0.0671],\n",
            "        [ 0.3182,  0.1086,  0.3645, -0.2975,  0.2042],\n",
            "        [ 0.2835,  0.1514,  0.1516, -0.1964,  0.1963],\n",
            "        [ 0.1800,  0.0043,  0.1794, -0.2360,  0.0323],\n",
            "        [ 0.2227,  0.1228,  0.1117, -0.3470,  0.1264],\n",
            "        [ 0.3062,  0.0615,  0.2056, -0.2043,  0.0620],\n",
            "        [ 0.2391,  0.1339,  0.0988, -0.1533,  0.0171]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "### Define the Neural Network using Sequential\n",
        "\n",
        "sequential_model = nn.Sequential(\n",
        "    nn.Linear(20,64),  #input layer(20 --> 64)\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64,32),   ## 64 --> 32\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32,5)    ## 32 --> 5 ouput classes\n",
        "\n",
        ")\n",
        "\n",
        "print(sequential_model)\n",
        "\n",
        "\n",
        "input_data = torch.randn(10,20) #10 Row, 20 features in each row\n",
        "output = sequential_model(input_data)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVAWF_dofzJ8",
        "outputId": "b8f4d1a0-ae49-4bae-df90-cbdaa54857ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[1.9368]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.2283], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(model.linear.weight)\n",
        "print(model.linear.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vPdyUgWgUm0",
        "outputId": "7699439c-e638-4c19-ce6b-9c03c61cdc36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FunctionalModule(\n",
            "  (fc1): Linear(in_features=20, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=5, bias=True)\n",
            "  (ReLU): ReLU()\n",
            ")\n",
            "tensor([[-0.0006,  0.0331,  0.1105, -0.1722,  0.0661],\n",
            "        [ 0.1740,  0.1321,  0.1100, -0.2247,  0.1816],\n",
            "        [-0.0784,  0.1688,  0.1944, -0.1824,  0.0364],\n",
            "        [ 0.0634,  0.0294,  0.1132, -0.2122, -0.0567],\n",
            "        [ 0.2408,  0.0818,  0.3304, -0.1522,  0.0737],\n",
            "        [ 0.0460,  0.0505,  0.2610, -0.1144, -0.0662],\n",
            "        [ 0.1011,  0.1199,  0.0711, -0.2532,  0.0255],\n",
            "        [ 0.1145,  0.0599,  0.1113, -0.2892,  0.2350],\n",
            "        [-0.1126,  0.0726,  0.1893, -0.1516,  0.0698],\n",
            "        [-0.0616, -0.0132,  0.3650, -0.2243,  0.0844]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "## Functional API\n",
        "\n",
        "class FunctionalModule(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FunctionalModule,self).__init__()\n",
        "    self.fc1 = nn.Linear(20,64)\n",
        "    self.fc2 = nn.Linear(64,32)\n",
        "    self.fc3 = nn.Linear(32,5)\n",
        "    self.ReLU = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    x = self.ReLU(self.fc1(x))\n",
        "    x = self.ReLU(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "functional_model = FunctionalModule()\n",
        "print(functional_model)\n",
        "\n",
        "input_data = torch.randn(10,20)\n",
        "output = functional_model(input_data)\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MultiClass Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('GPU is present')\n",
        "else:\n",
        "    print('CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "x = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = torch.tensor(x,dtype=torch.float32)\n",
        "Y= torch.tensor(y,dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(type(x))\n",
        "print(type(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ]
        }
      ],
      "source": [
        "print(iris.target_names)\n",
        "print(iris.feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "print(type(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "x_train_scaler = torch.tensor(scaler.fit_transform(x_train),dtype=torch.float32)\n",
        "x_test_scaler = torch.tensor(scaler.transform(x_test),dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "torch.Size([30, 4])\n"
          ]
        }
      ],
      "source": [
        "print(x_train_scaler.shape[1])\n",
        "print(x_test_scaler.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(iris.target_names)\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "100\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet,self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size,hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size,num_classes)\n",
        "        self.ReLU = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x1= self.ReLU(self.layer1(x))\n",
        "        x2= self.layer2(x1)\n",
        "        return x2\n",
        "    \n",
        "input_size = x_train_scaler.shape[1]\n",
        "hidden_size = 100\n",
        "num_classes = len(iris.target_names)\n",
        "\n",
        "print(input_size)\n",
        "print(hidden_size)\n",
        "print(num_classes)\n",
        "\n",
        "model = NeuralNet(input_size,hidden_size,num_classes)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimiser = optim.Adam(model.parameters(),lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epoch = 100\n",
        "num_batch = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(x_train,y_train):\n",
        "    for epoch in range(num_epoch):\n",
        "        output = model(x_train)\n",
        "        loss = criterion(output,y_train)\n",
        "        optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        print(f'Epoch ---> {epoch+1} : Loss ----> {loss.item() : .4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch ---> 1 : Loss ---->  0.9406\n",
            "Epoch ---> 2 : Loss ---->  0.7456\n",
            "Epoch ---> 3 : Loss ---->  0.6161\n",
            "Epoch ---> 4 : Loss ---->  0.5314\n",
            "Epoch ---> 5 : Loss ---->  0.4732\n",
            "Epoch ---> 6 : Loss ---->  0.4294\n",
            "Epoch ---> 7 : Loss ---->  0.3934\n",
            "Epoch ---> 8 : Loss ---->  0.3622\n",
            "Epoch ---> 9 : Loss ---->  0.3350\n",
            "Epoch ---> 10 : Loss ---->  0.3120\n",
            "Epoch ---> 11 : Loss ---->  0.2932\n",
            "Epoch ---> 12 : Loss ---->  0.2780\n",
            "Epoch ---> 13 : Loss ---->  0.2651\n",
            "Epoch ---> 14 : Loss ---->  0.2529\n",
            "Epoch ---> 15 : Loss ---->  0.2407\n",
            "Epoch ---> 16 : Loss ---->  0.2279\n",
            "Epoch ---> 17 : Loss ---->  0.2150\n",
            "Epoch ---> 18 : Loss ---->  0.2027\n",
            "Epoch ---> 19 : Loss ---->  0.1912\n",
            "Epoch ---> 20 : Loss ---->  0.1806\n",
            "Epoch ---> 21 : Loss ---->  0.1706\n",
            "Epoch ---> 22 : Loss ---->  0.1605\n",
            "Epoch ---> 23 : Loss ---->  0.1503\n",
            "Epoch ---> 24 : Loss ---->  0.1403\n",
            "Epoch ---> 25 : Loss ---->  0.1307\n",
            "Epoch ---> 26 : Loss ---->  0.1223\n",
            "Epoch ---> 27 : Loss ---->  0.1151\n",
            "Epoch ---> 28 : Loss ---->  0.1088\n",
            "Epoch ---> 29 : Loss ---->  0.1030\n",
            "Epoch ---> 30 : Loss ---->  0.0974\n",
            "Epoch ---> 31 : Loss ---->  0.0923\n",
            "Epoch ---> 32 : Loss ---->  0.0875\n",
            "Epoch ---> 33 : Loss ---->  0.0833\n",
            "Epoch ---> 34 : Loss ---->  0.0795\n",
            "Epoch ---> 35 : Loss ---->  0.0757\n",
            "Epoch ---> 36 : Loss ---->  0.0720\n",
            "Epoch ---> 37 : Loss ---->  0.0684\n",
            "Epoch ---> 38 : Loss ---->  0.0652\n",
            "Epoch ---> 39 : Loss ---->  0.0623\n",
            "Epoch ---> 40 : Loss ---->  0.0599\n",
            "Epoch ---> 41 : Loss ---->  0.0578\n",
            "Epoch ---> 42 : Loss ---->  0.0558\n",
            "Epoch ---> 43 : Loss ---->  0.0540\n",
            "Epoch ---> 44 : Loss ---->  0.0523\n",
            "Epoch ---> 45 : Loss ---->  0.0508\n",
            "Epoch ---> 46 : Loss ---->  0.0493\n",
            "Epoch ---> 47 : Loss ---->  0.0480\n",
            "Epoch ---> 48 : Loss ---->  0.0468\n",
            "Epoch ---> 49 : Loss ---->  0.0456\n",
            "Epoch ---> 50 : Loss ---->  0.0445\n",
            "Epoch ---> 51 : Loss ---->  0.0434\n",
            "Epoch ---> 52 : Loss ---->  0.0425\n",
            "Epoch ---> 53 : Loss ---->  0.0417\n",
            "Epoch ---> 54 : Loss ---->  0.0410\n",
            "Epoch ---> 55 : Loss ---->  0.0404\n",
            "Epoch ---> 56 : Loss ---->  0.0397\n",
            "Epoch ---> 57 : Loss ---->  0.0391\n",
            "Epoch ---> 58 : Loss ---->  0.0386\n",
            "Epoch ---> 59 : Loss ---->  0.0380\n",
            "Epoch ---> 60 : Loss ---->  0.0375\n",
            "Epoch ---> 61 : Loss ---->  0.0371\n",
            "Epoch ---> 62 : Loss ---->  0.0366\n",
            "Epoch ---> 63 : Loss ---->  0.0362\n",
            "Epoch ---> 64 : Loss ---->  0.0357\n",
            "Epoch ---> 65 : Loss ---->  0.0353\n",
            "Epoch ---> 66 : Loss ---->  0.0350\n",
            "Epoch ---> 67 : Loss ---->  0.0346\n",
            "Epoch ---> 68 : Loss ---->  0.0342\n",
            "Epoch ---> 69 : Loss ---->  0.0339\n",
            "Epoch ---> 70 : Loss ---->  0.0336\n",
            "Epoch ---> 71 : Loss ---->  0.0333\n",
            "Epoch ---> 72 : Loss ---->  0.0330\n",
            "Epoch ---> 73 : Loss ---->  0.0327\n",
            "Epoch ---> 74 : Loss ---->  0.0325\n",
            "Epoch ---> 75 : Loss ---->  0.0322\n",
            "Epoch ---> 76 : Loss ---->  0.0320\n",
            "Epoch ---> 77 : Loss ---->  0.0317\n",
            "Epoch ---> 78 : Loss ---->  0.0315\n",
            "Epoch ---> 79 : Loss ---->  0.0313\n",
            "Epoch ---> 80 : Loss ---->  0.0310\n",
            "Epoch ---> 81 : Loss ---->  0.0308\n",
            "Epoch ---> 82 : Loss ---->  0.0306\n",
            "Epoch ---> 83 : Loss ---->  0.0304\n",
            "Epoch ---> 84 : Loss ---->  0.0303\n",
            "Epoch ---> 85 : Loss ---->  0.0301\n",
            "Epoch ---> 86 : Loss ---->  0.0299\n",
            "Epoch ---> 87 : Loss ---->  0.0297\n",
            "Epoch ---> 88 : Loss ---->  0.0296\n",
            "Epoch ---> 89 : Loss ---->  0.0294\n",
            "Epoch ---> 90 : Loss ---->  0.0293\n",
            "Epoch ---> 91 : Loss ---->  0.0291\n",
            "Epoch ---> 92 : Loss ---->  0.0290\n",
            "Epoch ---> 93 : Loss ---->  0.0288\n",
            "Epoch ---> 94 : Loss ---->  0.0287\n",
            "Epoch ---> 95 : Loss ---->  0.0285\n",
            "Epoch ---> 96 : Loss ---->  0.0284\n",
            "Epoch ---> 97 : Loss ---->  0.0283\n",
            "Epoch ---> 98 : Loss ---->  0.0281\n",
            "Epoch ---> 99 : Loss ---->  0.0280\n",
            "Epoch ---> 100 : Loss ---->  0.0279\n"
          ]
        }
      ],
      "source": [
        "train(x_train_scaler,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "50 70 50\n",
            "3\n",
            "NeuralNetAdvance(\n",
            "  (layer1): Linear(in_features=4, out_features=50, bias=True)\n",
            "  (layer2): Linear(in_features=50, out_features=70, bias=True)\n",
            "  (layer3): Linear(in_features=70, out_features=50, bias=True)\n",
            "  (layer4): Linear(in_features=50, out_features=3, bias=True)\n",
            "  (ReLU): ReLU()\n",
            "  (dropout_1): Dropout(p=0.3, inplace=False)\n",
            "  (dropout_2): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class NeuralNetAdvance(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size_0, hidden_size_1, hidden_size_2, num_classes):\n",
        "        super(NeuralNetAdvance,self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size,hidden_size_0)\n",
        "        self.layer2 = nn.Linear(hidden_size_0,hidden_size_1)\n",
        "        self.layer3 = nn.Linear(hidden_size_1,hidden_size_2)\n",
        "        self.layer4 = nn.Linear(hidden_size_2,num_classes)\n",
        "        self.ReLU = nn.ReLU()\n",
        "        self.dropout_1 = nn.Dropout(p=0.3)\n",
        "        self.dropout_2 = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x1= self.ReLU(self.layer1(x))\n",
        "        x1 = self.dropout_1(x1)\n",
        "        x2= self.ReLU(self.layer2(x1))\n",
        "        x2 = self.dropout_2(x2)\n",
        "        x3= self.ReLU(self.layer3(x2))\n",
        "        x3 = self.dropout_1(x3)\n",
        "        x4= self.layer4(x3)\n",
        "        return x4\n",
        "    \n",
        "input_size = x_train_scaler.shape[1]\n",
        "hidden_size_0 = 50\n",
        "hidden_size_1 = 70\n",
        "hidden_size_2 = 50\n",
        "num_classes = len(iris.target_names)\n",
        "\n",
        "print(input_size)\n",
        "print(hidden_size_0,hidden_size_1, hidden_size_2)\n",
        "print(num_classes)\n",
        "\n",
        "model = NeuralNetAdvance(input_size,hidden_size_0, hidden_size_1, hidden_size_2 ,num_classes)\n",
        "print(model)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimiser = optim.Adam(model.parameters(),lr=0.01)\n",
        "num_epoch = 100\n",
        "\n",
        "def train_model(x,y):\n",
        "    for epoch in range(num_epoch):\n",
        "        output = model(x_train_scaler)\n",
        "        loss = criterion(output,y_train)\n",
        "        optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        print(f'Epochs ---> {epoch} : Loss ----> {loss.item(): .4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs ---> 0 : Loss ---->  1.1135\n",
            "Epochs ---> 1 : Loss ---->  1.0106\n",
            "Epochs ---> 2 : Loss ---->  0.9112\n",
            "Epochs ---> 3 : Loss ---->  0.7559\n",
            "Epochs ---> 4 : Loss ---->  0.6129\n",
            "Epochs ---> 5 : Loss ---->  0.5202\n",
            "Epochs ---> 6 : Loss ---->  0.4714\n",
            "Epochs ---> 7 : Loss ---->  0.4207\n",
            "Epochs ---> 8 : Loss ---->  0.3990\n",
            "Epochs ---> 9 : Loss ---->  0.3968\n",
            "Epochs ---> 10 : Loss ---->  0.3186\n",
            "Epochs ---> 11 : Loss ---->  0.3840\n",
            "Epochs ---> 12 : Loss ---->  0.3228\n",
            "Epochs ---> 13 : Loss ---->  0.3128\n",
            "Epochs ---> 14 : Loss ---->  0.2431\n",
            "Epochs ---> 15 : Loss ---->  0.2408\n",
            "Epochs ---> 16 : Loss ---->  0.2367\n",
            "Epochs ---> 17 : Loss ---->  0.2827\n",
            "Epochs ---> 18 : Loss ---->  0.2517\n",
            "Epochs ---> 19 : Loss ---->  0.2628\n",
            "Epochs ---> 20 : Loss ---->  0.1819\n",
            "Epochs ---> 21 : Loss ---->  0.1576\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs ---> 22 : Loss ---->  0.1972\n",
            "Epochs ---> 23 : Loss ---->  0.1338\n",
            "Epochs ---> 24 : Loss ---->  0.1029\n",
            "Epochs ---> 25 : Loss ---->  0.1287\n",
            "Epochs ---> 26 : Loss ---->  0.1307\n",
            "Epochs ---> 27 : Loss ---->  0.1041\n",
            "Epochs ---> 28 : Loss ---->  0.1190\n",
            "Epochs ---> 29 : Loss ---->  0.1269\n",
            "Epochs ---> 30 : Loss ---->  0.0584\n",
            "Epochs ---> 31 : Loss ---->  0.0694\n",
            "Epochs ---> 32 : Loss ---->  0.1100\n",
            "Epochs ---> 33 : Loss ---->  0.0943\n",
            "Epochs ---> 34 : Loss ---->  0.1439\n",
            "Epochs ---> 35 : Loss ---->  0.1274\n",
            "Epochs ---> 36 : Loss ---->  0.0909\n",
            "Epochs ---> 37 : Loss ---->  0.1978\n",
            "Epochs ---> 38 : Loss ---->  0.0786\n",
            "Epochs ---> 39 : Loss ---->  0.0755\n",
            "Epochs ---> 40 : Loss ---->  0.1177\n",
            "Epochs ---> 41 : Loss ---->  0.1124\n",
            "Epochs ---> 42 : Loss ---->  0.0876\n",
            "Epochs ---> 43 : Loss ---->  0.1239\n",
            "Epochs ---> 44 : Loss ---->  0.1007\n",
            "Epochs ---> 45 : Loss ---->  0.0539\n",
            "Epochs ---> 46 : Loss ---->  0.0866\n",
            "Epochs ---> 47 : Loss ---->  0.0988\n",
            "Epochs ---> 48 : Loss ---->  0.1687\n",
            "Epochs ---> 49 : Loss ---->  0.1182\n",
            "Epochs ---> 50 : Loss ---->  0.0770\n",
            "Epochs ---> 51 : Loss ---->  0.0694\n",
            "Epochs ---> 52 : Loss ---->  0.1115\n",
            "Epochs ---> 53 : Loss ---->  0.0471\n",
            "Epochs ---> 54 : Loss ---->  0.0882\n",
            "Epochs ---> 55 : Loss ---->  0.0777\n",
            "Epochs ---> 56 : Loss ---->  0.0832\n",
            "Epochs ---> 57 : Loss ---->  0.0805\n",
            "Epochs ---> 58 : Loss ---->  0.0685\n",
            "Epochs ---> 59 : Loss ---->  0.1045\n",
            "Epochs ---> 60 : Loss ---->  0.0531\n",
            "Epochs ---> 61 : Loss ---->  0.0631\n",
            "Epochs ---> 62 : Loss ---->  0.0370\n",
            "Epochs ---> 63 : Loss ---->  0.0637\n",
            "Epochs ---> 64 : Loss ---->  0.0304\n",
            "Epochs ---> 65 : Loss ---->  0.0492\n",
            "Epochs ---> 66 : Loss ---->  0.0658\n",
            "Epochs ---> 67 : Loss ---->  0.0577\n",
            "Epochs ---> 68 : Loss ---->  0.0412\n",
            "Epochs ---> 69 : Loss ---->  0.0313\n",
            "Epochs ---> 70 : Loss ---->  0.1001\n",
            "Epochs ---> 71 : Loss ---->  0.0339\n",
            "Epochs ---> 72 : Loss ---->  0.0993\n",
            "Epochs ---> 73 : Loss ---->  0.0283\n",
            "Epochs ---> 74 : Loss ---->  0.0495\n",
            "Epochs ---> 75 : Loss ---->  0.0271\n",
            "Epochs ---> 76 : Loss ---->  0.0505\n",
            "Epochs ---> 77 : Loss ---->  0.0595\n",
            "Epochs ---> 78 : Loss ---->  0.0291\n",
            "Epochs ---> 79 : Loss ---->  0.0371\n",
            "Epochs ---> 80 : Loss ---->  0.0433\n",
            "Epochs ---> 81 : Loss ---->  0.0852\n",
            "Epochs ---> 82 : Loss ---->  0.0453\n",
            "Epochs ---> 83 : Loss ---->  0.0449\n",
            "Epochs ---> 84 : Loss ---->  0.0694\n",
            "Epochs ---> 85 : Loss ---->  0.0673\n",
            "Epochs ---> 86 : Loss ---->  0.0424\n",
            "Epochs ---> 87 : Loss ---->  0.0297\n",
            "Epochs ---> 88 : Loss ---->  0.0288\n",
            "Epochs ---> 89 : Loss ---->  0.0460\n",
            "Epochs ---> 90 : Loss ---->  0.0420\n",
            "Epochs ---> 91 : Loss ---->  0.0414\n",
            "Epochs ---> 92 : Loss ---->  0.0786\n",
            "Epochs ---> 93 : Loss ---->  0.0592\n",
            "Epochs ---> 94 : Loss ---->  0.0314\n",
            "Epochs ---> 95 : Loss ---->  0.0360\n",
            "Epochs ---> 96 : Loss ---->  0.0454\n",
            "Epochs ---> 97 : Loss ---->  0.0515\n",
            "Epochs ---> 98 : Loss ---->  0.0457\n",
            "Epochs ---> 99 : Loss ---->  0.0589\n"
          ]
        }
      ],
      "source": [
        "train_model(x_train_scaler,y_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
